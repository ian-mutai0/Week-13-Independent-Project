---
title: "E-Commerce Project"
author: "Mr. Mutai"
date: "7/8/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# ASSESSMENT QUESTION 

Kira Plastinina is a Russian brand that is sold through a defunct chain of retail stores in Russia, Ukraine, Kazakhstan, Belarus, China, Philippines, and Armenia. The brand’s Sales and Marketing team would like to understand their customer’s behavior from data that they have collected over the past year. More specifically, they would like to learn the characteristics of customer groups.

# 1. DEFINING THE QUESTION 

## i) Defining the Specific Data Analytic Question

## ii) Defining the Metric for Success

## iii) Understanding the Context

## iv) Recording the Experimental Design


# 2. IMPORTING THE RELEVANT LIBRARIES

```{r library}
library(data.table)
library(ggplot2)
library(caret)
library(caretEnsemble)
library(psych)
library(Amelia)
library(mice)
library(GGally)
library(rpart)
```

# 3. DATA SOURCING

```{r}
commerce <- fread('http://bit.ly/EcommerceCustomersDataset')

# View the dataset in our environment
View(commerce)
```

# 4. PREVIEWING THE DATASET

i)  The top 6 rows in our dataset

```{r}
head(commerce)
```

ii) The bottom 6 rows in our dataset

```{r}
tail(commerce)
```

iii) The shape of the dataset

```{r}
dim(commerce)
```

Our dataset has 12330 rows and 18 columns. 

iv) The datatypes of the columns in our dataset

```{r}
str(commerce)
```

We have 2 logical columns, 7 numeric columns, 7 integer columns and 2 columns of the datatype character. 

- Before cleaning our dataset, we can go ahead and convert the datatypes of some of our numerical columns and make them categorical for better analysis. 

```{r}
commerce$OperatingSystems <- as.character(commerce$OperatingSystems)
commerce$Browser <- as.character(commerce$Browser)
commerce$Region <- as.character(commerce$Region)
commerce$TrafficType <- as.character(commerce$TrafficType)
```

# 5. CLEANING THE DATASET

## Checking for null values in the dataset

```{r}
colSums(is.na(commerce))
```

From the code above, we can tell that we have 14 missing values in each of the following 8 columns namely : "Administrative", "Administrative_Duration", "Informational", "Informational_Duration", "ProductRelated", "ProductRelated_Duration", "BounceRates" and "ExitRates".

### Dealing with the missing values in our dataset

```{r}
com <- na.omit(commerce)
dim(commerce)
dim(com)
```

We decided to omit the missing values from our initial dataset and use the new dataset for analysis and modelling. 

## Checking for duplicated rows in our dataset

```{r}
duplicated_rows <- com[(duplicated(com))]
duplicated_rows
```

- We can tell that we have 117 duplicated rows which we will go ahead and drop them since they will distort our analysis. 

### Dropping the duplicated rows

```{r}
# We create a new dataset that holds the unique values in our dataset
new_com <- unique(com)
dim(new_com)
```

- After dropping the duplicated rows, we go ahead to use the new_com dataset for analysis. 

## Checking for outliers

```{r}
#par(mfrow = c(4,3), mar = c(5,4,3,3))

# Finding all columns that are numerical/not strings & subsetting to new dataframe
#numerical_col <- new_com[, sapply(new_com, is.numeric)]

numerical_col <- subset(new_com, select = c(1,2,3,4,5,6,7,8,9,10))
#boxplot(numerical_col, main='BoxPlots')

```

```{r}
boxplot(new_col$`Administrative Duration`)
```

# 6. EXPLORATORY DATA ANALYSIS

## A. UNIVARIATE DATA ANALYSIS

### Measures of Central Tendency

#### i) Mean 

```{r}
library(dplyr)

new_com %>% summarise_if(is.numeric, mean)
```

#### ii) Mode

```{r}
getmode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}

new_com %>% summarise_if(is.numeric, getmode)
```

#### iii) Median

```{r}
new_com %>% summarise_if(is.numeric, median)
```


### Measures of Dispersion

#### i) Range

```{r}
new_com %>% summarise_if(is.numeric, range)
```

#### ii) Quantiles

```{r}
new_com %>% summarise_if(is.numeric, quantile)
```

#### iii) Variance

```{r}
new_com %>% summarise_if(is.numeric, var)
```

#### iv) Standard Deviation

```{r}
new_com %>% summarise_if(is.numeric, sd)
```

### Frequency Tables

```{r}
month <- table(new_com$Month)
month
```

```{r}
os <- table(new_com$OperatingSystems)
os
```

```{r}
browser <- table(new_com$Browser)
browser
```

```{r}
region <- table(new_com$Region)
region
```

```{r}
traffic <- table(new_com$TrafficType)
traffic
```

```{r}
visitor <- table(new_com$VisitorType)
visitor
```

```{r}
weekend <- table(new_com$Weekend)
weekend
```

```{r}
revenue <- table(new_com$Revenue)
revenue
```

### Graphical Plots

#### i) Bar Charts

```{r, echo = FALSE}
# Then we plot a bar chart 
barplot(revenue, xlab ='Revenue', ylab ='Count', main ='Revenue Bar Chart')
```

```{r, echo = FALSE}
# Then we plot a bar chart 
barplot(visitor, xlab ='Visitor', ylab ='Count', main ='Visitor Bar Chart')
```

```{r, echo = FALSE}
# Then we plot a bar chart 
barplot(month, xlab ='Month', ylab ='Frequency', main ='Month Bar Chart')
```

```{r, echo = FALSE}
# Then we plot a bar chart 
barplot(weekend, xlab ='Weekend', ylab ='Count', main ='Weekend Bar Chart')
```


## 2. BIVARIATE DATA ANALYSIS

### Covariance

```{r}

```





# 7. IMPLEMENTING THE SOLUTION

Perform clustering and upon implementation, provide comparisons between the approaches learned this week i.e. K-Means clustering vs Hierarchical clustering highlighting the strengths and limitations of each approach in the context of your analysis. 

## 1. K - Means Clustering

```{r}
# normalizing the data
normalize <- function(x){
  return ((x-min(x)) / (max(x)-min(x)))
}

com.norm <- normalize(numerical_col)
```

```{r}
# this step was added because finding the optimum number of clusters took sometime. therefore taking a random sample of 1000 
Com <- com.norm[sample(nrow(com.norm), size=1300), ]
head(Com)
```

### K means Clustering
```{r}
# Loading the required libraries
library(factoextra)
library(NbClust)
library (cluster)
```


```{r}
# Elbow method
fviz_nbclust(Com, kmeans, method = "wss") +
            geom_vline(xintercept = 3, linetype = 2)+
            labs(subtitle = "Elbow method")
```

```{r}
# Silhouette method
fviz_nbclust(rand_df, kmeans, method = "silhouette")+
  labs(subtitle = "Silhouette method")
```

```{r}
# Gap statistic
# nboot = 50 to keep the function speedy. 

set.seed(123)
fviz_nbclust(rand_df, kmeans, nstart = 25,  method = "gap_stat", nboot = 500)+
  labs(subtitle = "Gap statistic method")
```

```{r}
# choosing the best number of clusters
nb<-NbClust(data = rand_df, distance = "euclidean",
        min.nc = 2, max.nc = 15, method = "kmeans")

fviz_nbclust(nb)
```

```{r}

km <- kmeans(df.norm,3,iter.max = 10, nstart = 25)
km
```

```{r}
#plot results of final k-means model
fviz_cluster(km, data = df.new)
```






































